{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "88bipKnL5DvJ"
      },
      "outputs": [],
      "source": [
        "#Importing Modules\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.utils import save_image\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets,transforms\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating the model\n",
        "class VAEmodel(nn.Module):\n",
        "  def __init__(self):\n",
        "   super().__init__()\n",
        "\n",
        "   self.common_fc=nn.Sequential(\n",
        "       nn.Linear(784,196),\n",
        "       nn.Tanh(),\n",
        "       nn.Linear(196,48),\n",
        "       nn.Tanh()\n",
        "   )\n",
        "   self.mean_fc=nn.Sequential(  #For the mean part of VAE\n",
        "       nn.Linear(48,16),\n",
        "       nn.Tanh(),\n",
        "       nn.Linear(16,2)\n",
        "   )\n",
        "   self.log_fc=nn.Sequential(  #Logarithm of variance\n",
        "       nn.Linear(48,16),\n",
        "       nn.Tanh(),\n",
        "       nn.Linear(16,2)\n",
        "   )\n",
        "   self.decoder_fc=nn.Sequential(\n",
        "       nn.Linear(2,16),\n",
        "       nn.Tanh(),\n",
        "       nn.Linear(16,48),\n",
        "       nn.Tanh(),\n",
        "       nn.Linear(48,196),\n",
        "       nn.Tanh(),\n",
        "       nn.Linear(196,784),\n",
        "       nn.Tanh(),\n",
        "   )\n",
        "\n",
        "  def forward(self,x):\n",
        "    mean, log_var=self.encode(x)\n",
        "    z=self.sample(mean,log_var)\n",
        "    out= self.decode(z)\n",
        "    return mean,log_var,out\n",
        "\n",
        "  def encode(self,x): #Encoding part\n",
        "    out=self.common_fc(torch.flatten(x,start_dim=1))\n",
        "    mean=self.mean_fc(out)\n",
        "    log_var=self.log_fc(out)\n",
        "    return mean, log_var\n",
        "\n",
        "  def sample(self,mean,log_var): #Generating data using mean and standard deviation\n",
        "    std=torch.exp(0.5*log_var)\n",
        "    z=torch.randn_like(std)\n",
        "    z=z*std+mean\n",
        "    return z\n",
        "\n",
        "  def decode(self,z): #Decoding to generate an image\n",
        "    out=self.decoder_fc(z)\n",
        "    out=out.reshape(z.size(0),28,28)\n",
        "    return out\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vdTslUkN63LW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train_vae():\n",
        "  transform=transforms.ToTensor()\n",
        "  mnist_tr=datasets.MNIST(root='\\data',transform=transform,download=True,train=True) #Getting training data\n",
        "\n",
        "  mnist_ts=datasets.MNIST(root='\\data',transform=transform,download=True,train=False) #Getting testing data\n",
        "\n",
        "  train_data=DataLoader(mnist_tr.data,batch_size=64)\n",
        "\n",
        "  test_data=(mnist_ts.data-127.5)/127.5 #Scaling from -1 to 1\n",
        "\n",
        "  n_epochs=8\n",
        "  model=VAEmodel()\n",
        "  opti=optim.Adam(model.parameters(),lr=1e-3) #Defining optimizer function\n",
        "  criteria=nn.MSELoss()\n",
        "\n",
        "  recon=[] #Used to store the Mean Square error\n",
        "  kl=[]    #Storing the KL Dvergence error\n",
        "  loss=[]  #Storing the total error (MSE and KL Divergence error)\n",
        "\n",
        "  for epoch in range(n_epochs):\n",
        "   for id, image in enumerate(train_data):\n",
        "    image=image.float()\n",
        "    image=(image-127.5)/127.5\n",
        "    mean,log_var,out=model(image) #Getting the mean,log variance and output\n",
        "    kl_loss=torch.mean(0.5*torch.sum(torch.exp(log_var)+mean**2-1-log_var,dim=-1)) #Calculating KL loss\n",
        "    r_loss=criteria(out,image)\n",
        "    l=r_loss+0.00001*kl_loss #Actual loss function\n",
        "    recon.append(r_loss.item())\n",
        "    kl.append(kl_loss.item())\n",
        "    loss.append(l.item())\n",
        "    l.backward() #Calculating Gradients\n",
        "    opti.step()  #Gradient Descent\n",
        "    opti.zero_grad() #Restoring gradient's to 0\n",
        "\n",
        "   print(f'Epoch{epoch} done ')\n",
        "\n",
        "  idxs=torch.randint(0,len(test_data)-1,(100,))\n",
        "  ims=(test_data[idxs]).float() #Getting test image\n",
        "  _,_,gen=model(ims)\n",
        "\n",
        "  ims=(ims+1)/2\n",
        "  gray=ims.unsqueeze(1)\n",
        "  gen=1-(gen+1)/2\n",
        "  print(ims.shape)\n",
        "\n",
        "  save_image(gray[:],\"saved.png\",nrow=10) #Storing the outcomes of 100 test images\n",
        "\n",
        "train_vae()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-OaJ11vm_5KJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98bd892e-4b01-4b25-faea-b18cc014405f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to \\data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:01<00:00, 8924362.04it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting \\data/MNIST/raw/train-images-idx3-ubyte.gz to \\data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to \\data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 2266548.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting \\data/MNIST/raw/train-labels-idx1-ubyte.gz to \\data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to \\data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 12515343.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting \\data/MNIST/raw/t10k-images-idx3-ubyte.gz to \\data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to \\data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 5418239.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting \\data/MNIST/raw/t10k-labels-idx1-ubyte.gz to \\data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch0 done \n",
            "Epoch1 done \n",
            "Epoch2 done \n",
            "Epoch3 done \n",
            "Epoch4 done \n",
            "Epoch5 done \n",
            "Epoch6 done \n",
            "Epoch7 done \n",
            "torch.Size([100, 28, 28])\n"
          ]
        }
      ]
    }
  ]
}